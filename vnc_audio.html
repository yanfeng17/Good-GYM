<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Good-GYM</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html,
        body {
            width: 100%;
            height: 100%;
            overflow: hidden;
            background: #1a1a2e;
            font-family: 'Segoe UI', system-ui, sans-serif;
        }

        #vnc-frame {
            width: 100%;
            height: 100%;
            border: none;
        }

        #audio-status {
            position: fixed;
            top: 10px;
            right: 10px;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 12px;
            z-index: 1000;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .audio-disconnected {
            background: #e74c3c;
            color: white;
        }

        .audio-connected {
            background: #27ae60;
            color: white;
        }

        .audio-pending {
            background: #f39c12;
            color: white;
        }



        #debug-panel {
            position: fixed;
            bottom: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.8);
            color: #0f0;
            padding: 10px;
            font-family: monospace;
            font-size: 11px;
            max-width: 400px;
            max-height: 150px;
            overflow-y: auto;
            border-radius: 8px;
            z-index: 1000;
            display: none;
        }

        #debug-panel.visible {
            display: block;
        }
    </style>
</head>

<body>
    <!-- Audio init overlay removed - auto-initialization enabled -->


    <!-- Audio status indicator -->
    <div id="audio-status" class="audio-disconnected" title="ÁÇπÂáªÈáçËøûÊàñÂêØÁî®Èü≥È¢ë">
        üîá Èü≥È¢ëÊú™ËøûÊé•
    </div>

    <!-- Debug panel -->
    <div id="debug-panel"></div>

    <!-- VNC iframe - URL set dynamically -->
    <iframe id="vnc-frame" allow="fullscreen"></iframe>

    <script>
        // Set VNC iframe URL to port 6081 (noVNC server)
        const vncFrame = document.getElementById('vnc-frame');
        const vncUrl = `${window.location.protocol}//${window.location.hostname}:6081/vnc.html?autoconnect=true&resize=scale`;
        vncFrame.src = vncUrl;
        console.log('[Audio] VNC URL:', vncUrl);
    </script>

    <script>
        // ============ Configuration ============
        const WS_PORT = 8765;
        const AUDIO_HTTP_PORT = 8080;
        const RECONNECT_INTERVAL = 3000;

        // ============ State ============
        let audioContext = null;
        let audioBuffers = {};
        let wsConnection = null;
        let audioEnabled = false;
        let debugVisible = false;

        // Mobile Audio Unlock
        function unlockAudio() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    debugLog('AudioContext resumed (User Gesture)');
                });
            }
            // Play silent buffer to unlock iOS audio
            const buffer = audioContext.createBuffer(1, 1, 22050);
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.start(0);
        }

        // ============ Debug Logging ============
        const debugPanel = document.getElementById('debug-panel');
        function debugLog(msg) {
            const time = new Date().toLocaleTimeString();
            const line = document.createElement('div');
            line.textContent = `[${time}] ${msg}`;
            debugPanel.appendChild(line);
            debugPanel.scrollTop = debugPanel.scrollHeight;
            console.log(`[Audio] ${msg}`);

            // Keep only last 20 lines
            while (debugPanel.children.length > 20) {
                debugPanel.removeChild(debugPanel.firstChild);
            }
        }

        // ============ Audio Status Update ============
        const statusEl = document.getElementById('audio-status');
        function updateStatus(status, text) {
            statusEl.className = `audio-${status}`;
            statusEl.textContent = text;
        }

        // Toggle debug panel
        statusEl.onclick = () => {
            debugVisible = !debugVisible;
            debugPanel.classList.toggle('visible', debugVisible);
        };

        // ============ Audio Context & Preload ============
        async function initAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                debugLog('AudioContext ÂàõÂª∫ÊàêÂäü');

                // Immediately resume AudioContext if possible
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                    debugLog('AudioContext Â∑≤ÊÅ¢Â§ç');
                }

                // Preload audio files (use relative path to avoid port issues)
                const audioFiles = ['count.mp3', 'succeed.mp3', 'milestone.mp3'];
                const baseUrl = '/assets';

                for (const file of audioFiles) {
                    try {
                        debugLog(`Âä†ËΩΩÈü≥È¢ë: ${file}`);
                        const response = await fetch(`${baseUrl}/${file}`);
                        if (!response.ok) throw new Error(`HTTP ${response.status}`);
                        const arrayBuffer = await response.arrayBuffer();
                        audioBuffers[file] = await audioContext.decodeAudioData(arrayBuffer);
                        debugLog(`‚úì Â∑≤Âä†ËΩΩ: ${file}`);
                    } catch (e) {
                        debugLog(`‚úó Âä†ËΩΩÂ§±Ë¥• ${file}: ${e.message}`);
                    }
                }

                audioEnabled = true;
                debugLog('Èü≥È¢ëÁ≥ªÁªüÂ∞±Áª™');
                return true;
            } catch (e) {
                debugLog(`‚úó AudioContext ÂàõÂª∫Â§±Ë¥•: ${e.message}`);
                return false;
            }
        }

        // ============ TTS Speech Synthesis ============
        let speechSynthesis = window.speechSynthesis;
        let currentCount = 0;
        let availableVoices = [];
        let chineseVoice = null;
        let isSpeaking = false;
        let speechQueue = [];

        // Wait for voices to be loaded
        function waitForVoices() {
            return new Promise((resolve) => {
                const voices = speechSynthesis.getVoices();
                if (voices.length > 0) {
                    debugLog(`‚úì ËØ≠Èü≥Â∫ìÂ∑≤Âä†ËΩΩ (${voices.length} ‰∏™ËØ≠Èü≥)`);
                    resolve(voices);
                } else {
                    debugLog('Á≠âÂæÖËØ≠Èü≥Â∫ìÂä†ËΩΩ...');
                    speechSynthesis.onvoiceschanged = () => {
                        const loadedVoices = speechSynthesis.getVoices();
                        debugLog(`‚úì ËØ≠Èü≥Â∫ìÂ∑≤Âä†ËΩΩ (${loadedVoices.length} ‰∏™ËØ≠Èü≥)`);
                        resolve(loadedVoices);
                    };

                    // Fallback timeout
                    setTimeout(() => {
                        const voices = speechSynthesis.getVoices();
                        if (voices.length === 0) {
                            debugLog('‚ö† ËØ≠Èü≥Â∫ìÂä†ËΩΩË∂ÖÊó∂,ÂèØËÉΩ‰∏çÊîØÊåÅ TTS');
                        }
                        resolve(voices);
                    }, 2000);
                }
            });
        }

        // Initialize TTS
        async function initTTS() {
            if (!speechSynthesis) {
                debugLog('‚ö† ÊµèËßàÂô®‰∏çÊîØÊåÅËØ≠Èü≥ÂêàÊàê');
                return false;
            }

            try {
                availableVoices = await waitForVoices();

                // Find Chinese voice
                chineseVoice = availableVoices.find(v =>
                    v.lang.includes('zh') || v.lang.includes('CN')
                );

                if (chineseVoice) {
                    debugLog(`‚úì ÊâæÂà∞‰∏≠ÊñáËØ≠Èü≥: ${chineseVoice.name} (${chineseVoice.lang})`);
                } else {
                    debugLog('‚ö† Êú™ÊâæÂà∞‰∏≠ÊñáËØ≠Èü≥,Â∞Ü‰ΩøÁî®ÈªòËÆ§ËØ≠Èü≥');
                    // List available voices for debugging
                    if (availableVoices.length > 0) {
                        debugLog(`ÂèØÁî®ËØ≠Èü≥: ${availableVoices.slice(0, 3).map(v => v.lang).join(', ')}`);
                    }
                }

                return true;
            } catch (e) {
                debugLog(`‚úó TTS ÂàùÂßãÂåñÂ§±Ë¥•: ${e.message}`);
                return false;
            }
        }

        // Process speech queue
        function processSpeechQueue() {
            if (isSpeaking || speechQueue.length === 0) {
                return;
            }

            isSpeaking = true;
            const text = speechQueue.shift();

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'zh-CN';
            utterance.rate = 1.2;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;

            if (chineseVoice) {
                utterance.voice = chineseVoice;
            }

            utterance.onend = () => {
                isSpeaking = false;
                debugLog(`‚úì TTS Êí≠Êä•ÂÆåÊàê: ${text}`);
                // Process next in queue
                if (speechQueue.length > 0) {
                    setTimeout(processSpeechQueue, 100);
                }
            };

            utterance.onerror = (e) => {
                isSpeaking = false;
                debugLog(`‚úó TTS Êí≠Êä•ÈîôËØØ: ${e.error}`);
                // Try next in queue
                if (speechQueue.length > 0) {
                    setTimeout(processSpeechQueue, 100);
                }
            };

            // Cancel any ongoing speech before starting new one
            speechSynthesis.cancel();
            speechSynthesis.speak(utterance);
            debugLog(`üó£Ô∏è TTS Êí≠Êä•: ${text}`);
        }

        function speakText(text) {
            if (!speechSynthesis) {
                debugLog('‚ö† ÊµèËßàÂô®‰∏çÊîØÊåÅËØ≠Èü≥ÂêàÊàê');
                return;
            }

            // Check if AudioContext is running
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    debugLog('AudioContext Â∑≤ÊÅ¢Â§ç(TTS)');
                });
            }

            // Add to queue
            speechQueue.push(text);

            // Limit queue size
            if (speechQueue.length > 3) {
                speechQueue.shift();
                debugLog('‚ö† ËØ≠Èü≥ÈòüÂàóËøáÈïø,‰∏¢ÂºÉÊóßÊ∂àÊÅØ');
            }

            processSpeechQueue();
        }


        function playSound(soundType, count) {
            debugLog(`Êî∂Âà∞Êí≠ÊîæËØ∑Ê±Ç: ${soundType}, count=${count}`);

            // If count is provided, try TTS first
            if (soundType === 'count' && count !== undefined) {
                const hasVoices = availableVoices.length > 0 || (window.speechSynthesis && window.speechSynthesis.getVoices().length > 0);

                if (window.speechSynthesis && hasVoices) {
                    currentCount = count;
                    speakText(`${count}`);  // Only announce the number
                    return;
                }
                debugLog('‚ö† TTS‰∏çÂèØÁî®(Êó†ËØ≠Èü≥Â∫ì)ÔºåÂõûÈÄÄÂà∞Èü≥È¢ëÊñá‰ª∂');
                // Fall through to below logic to play count.mp3
            }


            if (soundType === 'milestone' && count !== undefined) {
                const hasVoices = availableVoices.length > 0 || (window.speechSynthesis && window.speechSynthesis.getVoices().length > 0);

                if (window.speechSynthesis && hasVoices) {
                    speakText(`${count}`);  // Announce milestone count
                    return;
                }
                debugLog('‚ö† TTS‰∏çÂèØÁî®ÔºåÊí≠ÊîæÈáåÁ®ãÁ¢ëÈü≥È¢ëÊñá‰ª∂');
                // Fall through to play milestone.mp3
            }


            // Fallback to audio file for other sounds
            if (!audioEnabled || !audioContext) {
                debugLog(`‚ö† Èü≥È¢ëÊú™ÂêØÁî®ÔºåÊó†Ê≥ïÊí≠Êîæ ${soundType}`);
                return;
            }

            // Map sound type to file
            const fileMap = {
                'count': 'count.mp3',
                'succeed': 'succeed.mp3',
                'milestone': 'milestone.mp3'
            };

            const file = fileMap[soundType] || soundType;
            const buffer = audioBuffers[file];

            if (!buffer) {
                debugLog(`‚ö† Èü≥È¢ëÁºìÂÜ≤Âå∫Êú™ÊâæÂà∞: ${file}`);
                return;
            }

            try {
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);
                source.start(0);
                debugLog(`üîä Êí≠Êîæ: ${soundType}`);
            } catch (e) {
                debugLog(`‚úó Êí≠ÊîæÂ§±Ë¥•: ${e.message}`);
            }
        }

        // ============ WebSocket Connection ============
        function connectWebSocket() {
            const wsUrl = `ws://${window.location.hostname}:${WS_PORT}`;
            debugLog(`ËøûÊé• WebSocket: ${wsUrl}`);
            updateStatus('pending', 'üîÑ ËøûÊé•‰∏≠...');

            try {
                wsConnection = new WebSocket(wsUrl);

                wsConnection.onopen = () => {
                    debugLog('‚úì WebSocket Â∑≤ËøûÊé•');
                    updateStatus('connected', 'üîä Èü≥È¢ëÂ∑≤ËøûÊé•');
                };

                wsConnection.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        debugLog(`Êî∂Âà∞Ê∂àÊÅØ: ${data.type}`);

                        if (data.type === 'play_audio') {
                            playSound(data.sound, data.count);
                        } else if (data.type === 'connected') {
                            debugLog(`‚úì WebSocket Êè°ÊâãÊàêÂäü: ${data.message}`);
                        }
                    } catch (e) {
                        debugLog(`Ê∂àÊÅØËß£ÊûêÈîôËØØ: ${e.message}`);
                    }
                };

                wsConnection.onclose = () => {
                    debugLog('WebSocket Êñ≠ÂºÄ,Â∞ÜÈáçËøû...');
                    updateStatus('disconnected', 'üîá Èü≥È¢ëÊñ≠ÂºÄ');
                    wsConnection = null;
                    setTimeout(connectWebSocket, RECONNECT_INTERVAL);
                };

                wsConnection.onerror = (e) => {
                    debugLog(`WebSocket ÈîôËØØ: ${e.type}`);
                };

            } catch (e) {
                debugLog(`‚úó WebSocket ÂàõÂª∫Â§±Ë¥•: ${e.message}`);
                setTimeout(connectWebSocket, RECONNECT_INTERVAL);
            }
        }

        // ============ Mobile Detection ============
        function isMobileDevice() {
            return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        }

        // ============ Audio Unlock ============
        function unlockAudio() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    debugLog('AudioContext Â∑≤ÊÅ¢Â§ç (Áî®Êà∑ÊâãÂäø)');
                });
            }

            // Play silent buffer to unlock iOS audio
            if (audioContext) {
                try {
                    const buffer = audioContext.createBuffer(1, 1, 22050);
                    const source = audioContext.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.destination);
                    source.start(0);
                    debugLog('‚úì Êí≠ÊîæÈùôÈªòÁºìÂÜ≤Âå∫(Ëß£ÈîÅÈü≥È¢ë)');
                } catch (e) {
                    debugLog(`‚ö† Ëß£ÈîÅÈü≥È¢ëÂ§±Ë¥•: ${e.message}`);
                }
            }
        }

        // ============ Initialization ============
        async function startApp() {
            debugLog('==================== Â∫îÁî®ÂêØÂä® ====================');
            debugLog(`ËÆæÂ§áÁ±ªÂûã: ${isMobileDevice() ? 'ÁßªÂä®ËÆæÂ§á' : 'Ê°åÈù¢ËÆæÂ§á'}`);

            // Auto-connect flow
            updateStatus('pending', 'üîÑ ÂàùÂßãÂåñ‰∏≠...');

            try {
                // 1. Try to init AudioContext (might be suspended)
                await initAudio();

                // 2. Try to init TTS
                await initTTS();

                // 3. Connect WebSocket immediately
                connectWebSocket();

                // 4. Try to unlock immediately (works if page loaded via user action)
                unlockAudio();

            } catch (e) {
                debugLog(`‚úó Ëá™Âä®ÂàùÂßãÂåñÈîôËØØ: ${e.message}`);
            }
        }

        // ============ Event Listeners ============
        window.addEventListener('load', startApp);

        // Global interaction handler to unlock audio engine
        function onInteraction() {
            unlockAudio();
            // Optional: remove listeners once fully unlocked, but safe to keep
        }

        ['click', 'touchstart', 'keydown', 'mousedown'].forEach(event => {
            document.addEventListener(event, onInteraction, { once: false, passive: false });
        });

        // Enhanced unlock function
        function unlockAudio() {
            // 1. Resume AudioContext
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    debugLog('AudioContext Â∑≤ÊÅ¢Â§ç (‰∫§‰∫íËß¶Âèë)');
                });
            } else if (!audioContext) {
                // Try to init if missing
                initAudio();
            }

            // 2. Play silent buffer (Critical for iOS)
            if (audioContext) {
                try {
                    const buffer = audioContext.createBuffer(1, 1, 22050);
                    const source = audioContext.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.destination);
                    source.start(0);
                } catch (e) { }
            }

            // 3. Prime TTS (Critical for mobile)
            if (speechSynthesis && !isSpeaking) {
                // Speak empty string to unlock TTS engine
                const u = new SpeechSynthesisUtterance('');
                u.volume = 0;
                speechSynthesis.speak(u);
            }
        }

        // Status icon click handler (Manual Reconnect)
        statusEl.onclick = () => {
            unlockAudio(); // Always try to unlock

            if (!wsConnection || wsConnection.readyState !== WebSocket.OPEN) {
                connectWebSocket();
            }

            // Toggle debug only if long press or specific logic? 
            // For now, keep it simple: click = reconnect + unlock. 
            // Double click = debug? Let's just make debug explicit via console or a hidden gesture.
            // keeping toggle for now as requested by user previously, but prioritizing connect
            debugVisible = !debugVisible;
            debugPanel.classList.toggle('visible', debugVisible);
        };



        debugLog('È°µÈù¢Âä†ËΩΩÂÆåÊàê');
    </script>
</body>

</html>